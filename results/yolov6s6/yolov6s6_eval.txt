Namespace(data='../SeaDronesSee-Yolov8/test.yaml', weights='./runs/train/LaS2n/weights/best_ckpt.pt', batch_size=32, img_size=1280, conf_thres=0.03, iou_thres=0.65, task='val', device='0', half=False, save_dir='runs/val/', name='yolov6s6', test_load_size=638, letterbox_return_int=True, scale_exact=True, force_no_pad=True, not_infer_on_rect=True, reproduce_640_eval=True, eval_config_file='./configs/experiment/eval_640_repro.py', do_coco_metric=True, do_pr_metric=True, plot_curve=True, plot_confusion_matrix=True, verbose=True, config_file='')
Loading checkpoint from ./runs/train/LaS2n/weights/best_ckpt.pt

Fusing model...
/localHome/sezrship/anaconda3/envs/torch/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Switch model to deploy modality.
Model Summary: Params: 41.32M, Gflops: 197.53
Val: Checking formats of labels with 8 process(es): 
  0%|          | 0/3279 [00:00<?, ?it/s]2388 label(s) found, 0 label(s) missing, 685 label(s) empty, 0 invalid label files:  73%|███████▎  | 2388/3279 [00:00<00:00, 23605.16it/s]3279 label(s) found, 0 label(s) missing, 852 label(s) empty, 0 invalid label files: 100%|██████████| 3279/3279 [00:00<00:00, 25383.01it/s]
Convert to COCO format
  0%|          | 0/3279 [00:00<?, ?it/s]100%|██████████| 3279/3279 [00:00<00:00, 38938.41it/s]
Convert to COCO format finished. Resutls saved in /localHome/sezrship/YOLOv6/SeaDronesSee-Yolov8/annotations/instances_test.json
Val: Final numbers of valid images: 3279/ labels: 3279. 
0.6s for dataset initialization.
Inferencing model in val datasets.:   0%|               | 0/103 [00:00<?, ?it/s]Inferencing model in val datasets.:   1%|       | 1/103 [00:03<05:59,  3.53s/it]Inferencing model in val datasets.:   2%|▏      | 2/103 [00:04<03:08,  1.87s/it]Inferencing model in val datasets.:   3%|▏      | 3/103 [00:04<02:05,  1.26s/it]Inferencing model in val datasets.:   4%|▎      | 4/103 [00:05<01:27,  1.13it/s]Inferencing model in val datasets.:   5%|▎      | 5/103 [00:05<01:08,  1.42it/s]Inferencing model in val datasets.:   6%|▍      | 6/103 [00:05<00:54,  1.77it/s]Inferencing model in val datasets.:   7%|▍      | 7/103 [00:06<00:52,  1.84it/s]Inferencing model in val datasets.:   8%|▌      | 8/103 [00:06<00:45,  2.10it/s]Inferencing model in val datasets.:   9%|▌      | 9/103 [00:07<00:46,  2.02it/s]Inferencing model in val datasets.:  10%|▌     | 10/103 [00:07<00:41,  2.25it/s]Inferencing model in val datasets.:  11%|▋     | 11/103 [00:07<00:37,  2.43it/s]Inferencing model in val datasets.:  12%|▋     | 12/103 [00:08<00:38,  2.39it/s]Inferencing model in val datasets.:  13%|▊     | 13/103 [00:08<00:38,  2.32it/s]Inferencing model in val datasets.:  14%|▊     | 14/103 [00:09<00:37,  2.36it/s]Inferencing model in val datasets.:  15%|▊     | 15/103 [00:09<00:40,  2.15it/s]Inferencing model in val datasets.:  16%|▉     | 16/103 [00:09<00:37,  2.35it/s]Inferencing model in val datasets.:  17%|▉     | 17/103 [00:10<00:33,  2.54it/s]Inferencing model in val datasets.:  17%|█     | 18/103 [00:10<00:35,  2.42it/s]Inferencing model in val datasets.:  18%|█     | 19/103 [00:11<00:35,  2.37it/s]Inferencing model in val datasets.:  19%|█▏    | 20/103 [00:11<00:34,  2.41it/s]Inferencing model in val datasets.:  20%|█▏    | 21/103 [00:12<00:37,  2.18it/s]Inferencing model in val datasets.:  21%|█▎    | 22/103 [00:12<00:35,  2.29it/s]Inferencing model in val datasets.:  22%|█▎    | 23/103 [00:12<00:33,  2.40it/s]Inferencing model in val datasets.:  23%|█▍    | 24/103 [00:13<00:33,  2.38it/s]Inferencing model in val datasets.:  24%|█▍    | 25/103 [00:13<00:31,  2.49it/s]Inferencing model in val datasets.:  25%|█▌    | 26/103 [00:14<00:30,  2.56it/s]Inferencing model in val datasets.:  26%|█▌    | 27/103 [00:14<00:29,  2.60it/s]Inferencing model in val datasets.:  27%|█▋    | 28/103 [00:14<00:31,  2.35it/s]Inferencing model in val datasets.:  28%|█▋    | 29/103 [00:15<00:30,  2.46it/s]Inferencing model in val datasets.:  29%|█▋    | 30/103 [00:15<00:28,  2.55it/s]Inferencing model in val datasets.:  30%|█▊    | 31/103 [00:16<00:29,  2.42it/s]Inferencing model in val datasets.:  31%|█▊    | 32/103 [00:16<00:30,  2.36it/s]Inferencing model in val datasets.:  32%|█▉    | 33/103 [00:17<00:30,  2.32it/s]Inferencing model in val datasets.:  33%|█▉    | 34/103 [00:17<00:32,  2.12it/s]Inferencing model in val datasets.:  34%|██    | 35/103 [00:18<00:31,  2.18it/s]Inferencing model in val datasets.:  35%|██    | 36/103 [00:18<00:30,  2.22it/s]Inferencing model in val datasets.:  36%|██▏   | 37/103 [00:18<00:29,  2.23it/s]Inferencing model in val datasets.:  37%|██▏   | 38/103 [00:19<00:28,  2.31it/s]Inferencing model in val datasets.:  38%|██▎   | 39/103 [00:19<00:30,  2.09it/s]Inferencing model in val datasets.:  39%|██▎   | 40/103 [00:20<00:28,  2.22it/s]Inferencing model in val datasets.:  40%|██▍   | 41/103 [00:20<00:28,  2.21it/s]Inferencing model in val datasets.:  41%|██▍   | 42/103 [00:21<00:28,  2.15it/s]Inferencing model in val datasets.:  42%|██▌   | 43/103 [00:21<00:27,  2.20it/s]Inferencing model in val datasets.:  43%|██▌   | 44/103 [00:22<00:32,  1.83it/s]Inferencing model in val datasets.:  44%|██▌   | 45/103 [00:22<00:32,  1.81it/s]Inferencing model in val datasets.:  45%|██▋   | 46/103 [00:23<00:31,  1.83it/s]Inferencing model in val datasets.:  46%|██▋   | 47/103 [00:24<00:30,  1.81it/s]Inferencing model in val datasets.:  47%|██▊   | 48/103 [00:24<00:28,  1.92it/s]Inferencing model in val datasets.:  48%|██▊   | 49/103 [00:25<00:28,  1.92it/s]Inferencing model in val datasets.:  49%|██▉   | 50/103 [00:25<00:25,  2.06it/s]Inferencing model in val datasets.:  50%|██▉   | 51/103 [00:25<00:24,  2.13it/s]Inferencing model in val datasets.:  50%|███   | 52/103 [00:26<00:25,  1.98it/s]Inferencing model in val datasets.:  51%|███   | 53/103 [00:26<00:24,  2.04it/s]Inferencing model in val datasets.:  52%|███▏  | 54/103 [00:27<00:24,  1.96it/s]Inferencing model in val datasets.:  53%|███▏  | 55/103 [00:28<00:24,  1.96it/s]Inferencing model in val datasets.:  54%|███▎  | 56/103 [00:28<00:24,  1.89it/s]Inferencing model in val datasets.:  55%|███▎  | 57/103 [00:29<00:23,  1.95it/s]Inferencing model in val datasets.:  56%|███▍  | 58/103 [00:29<00:23,  1.95it/s]Inferencing model in val datasets.:  57%|███▍  | 59/103 [00:30<00:22,  1.95it/s]Inferencing model in val datasets.:  58%|███▍  | 60/103 [00:30<00:21,  2.03it/s]Inferencing model in val datasets.:  59%|███▌  | 61/103 [00:31<00:22,  1.86it/s]Inferencing model in val datasets.:  60%|███▌  | 62/103 [00:31<00:21,  1.94it/s]Inferencing model in val datasets.:  61%|███▋  | 63/103 [00:32<00:21,  1.89it/s]Inferencing model in val datasets.:  62%|███▋  | 64/103 [00:32<00:19,  1.96it/s]Inferencing model in val datasets.:  63%|███▊  | 65/103 [00:33<00:20,  1.83it/s]Inferencing model in val datasets.:  64%|███▊  | 66/103 [00:33<00:19,  1.89it/s]Inferencing model in val datasets.:  65%|███▉  | 67/103 [00:34<00:19,  1.88it/s]Inferencing model in val datasets.:  66%|███▉  | 68/103 [00:34<00:18,  1.93it/s]Inferencing model in val datasets.:  67%|████  | 69/103 [00:35<00:18,  1.81it/s]Inferencing model in val datasets.:  68%|████  | 70/103 [00:36<00:18,  1.79it/s]Inferencing model in val datasets.:  69%|████▏ | 71/103 [00:36<00:17,  1.80it/s]Inferencing model in val datasets.:  70%|████▏ | 72/103 [00:37<00:16,  1.83it/s]Inferencing model in val datasets.:  71%|████▎ | 73/103 [00:37<00:16,  1.80it/s]Inferencing model in val datasets.:  72%|████▎ | 74/103 [00:38<00:15,  1.86it/s]Inferencing model in val datasets.:  73%|████▎ | 75/103 [00:38<00:14,  1.91it/s]Inferencing model in val datasets.:  74%|████▍ | 76/103 [00:39<00:14,  1.86it/s]Inferencing model in val datasets.:  75%|████▍ | 77/103 [00:39<00:13,  1.88it/s]Inferencing model in val datasets.:  76%|████▌ | 78/103 [00:40<00:12,  1.92it/s]Inferencing model in val datasets.:  77%|████▌ | 79/103 [00:40<00:12,  1.99it/s]Inferencing model in val datasets.:  78%|████▋ | 80/103 [00:41<00:10,  2.12it/s]Inferencing model in val datasets.:  79%|████▋ | 81/103 [00:41<00:09,  2.22it/s]Inferencing model in val datasets.:  80%|████▊ | 82/103 [00:42<00:09,  2.12it/s]Inferencing model in val datasets.:  81%|████▊ | 83/103 [00:42<00:09,  2.21it/s]Inferencing model in val datasets.:  82%|████▉ | 84/103 [00:42<00:08,  2.13it/s]Inferencing model in val datasets.:  83%|████▉ | 85/103 [00:43<00:08,  2.14it/s]Inferencing model in val datasets.:  83%|█████ | 86/103 [00:43<00:07,  2.26it/s]Inferencing model in val datasets.:  84%|█████ | 87/103 [00:44<00:07,  2.07it/s]Inferencing model in val datasets.:  85%|█████▏| 88/103 [00:44<00:06,  2.21it/s]Inferencing model in val datasets.:  86%|█████▏| 89/103 [00:45<00:06,  2.19it/s]Inferencing model in val datasets.:  87%|█████▏| 90/103 [00:45<00:05,  2.17it/s]Inferencing model in val datasets.:  88%|█████▎| 91/103 [00:46<00:05,  2.25it/s]Inferencing model in val datasets.:  89%|█████▎| 92/103 [00:46<00:05,  2.07it/s]Inferencing model in val datasets.:  90%|█████▍| 93/103 [00:47<00:04,  2.14it/s]Inferencing model in val datasets.:  91%|█████▍| 94/103 [00:47<00:04,  2.17it/s]Inferencing model in val datasets.:  92%|█████▌| 95/103 [00:48<00:03,  2.15it/s]Inferencing model in val datasets.:  93%|█████▌| 96/103 [00:48<00:03,  2.11it/s]Inferencing model in val datasets.:  94%|█████▋| 97/103 [00:49<00:03,  1.92it/s]Inferencing model in val datasets.:  95%|█████▋| 98/103 [00:49<00:02,  1.97it/s]Inferencing model in val datasets.:  96%|█████▊| 99/103 [00:50<00:02,  1.98it/s]Inferencing model in val datasets.:  97%|████▊| 100/103 [00:50<00:01,  2.02it/s]Inferencing model in val datasets.:  98%|████▉| 101/103 [00:51<00:01,  1.87it/s]Inferencing model in val datasets.:  99%|████▉| 102/103 [00:51<00:00,  2.04it/s]Inferencing model in val datasets.: 100%|█████| 103/103 [00:51<00:00,  2.33it/s]Inferencing model in val datasets.: 100%|█████| 103/103 [00:51<00:00,  1.99it/s]
IOU 50 best mF1 thershold near 0.321.
Class                 Images      Labels     P@.5iou     R@.5iou    F1@.5iou      mAP@.5  mAP@.5:.95
all                     3279        8273       0.797       0.628       0.669       0.637       0.375
boat                    3279        2569       0.913       0.883       0.898       0.912       0.623
buoy                    3279         821        0.89        0.84       0.865       0.865       0.505
jetski                  3279         465       0.868       0.731       0.794       0.763       0.481
life_saving_appliances        3279         152       0.627      0.0855       0.151      0.0912      0.0524
swimmer                 3279        4266       0.686         0.6        0.64       0.555       0.213

Evaluating speed.
Average pre-process time: 0.27 ms
Average inference time: 4.99 ms
Average NMS time: 2.14 ms

Evaluating mAP by pycocotools.
Saving runs/val/yolov6s61/predictions.json...
Class           Labeled_images      Labels     P@.5iou     R@.5iou    F1@.5iou      mAP@.5  mAP@.5:.95
all                     2427        8273        0.66        0.68        0.67       0.636       0.375
boat                    1558        2569        0.93        0.87       0.899       0.908       0.621
buoy                     654         821        0.89        0.84       0.864       0.862       0.505
jetski                   465         465       0.915        0.71       0.799       0.761       0.481
life_saving_appliances         134         152       0.538        0.09       0.154      0.0952      0.0555
swimmer                 1209        4266       0.685         0.6        0.64       0.554       0.215
Results saved to runs/val/yolov6s61
loading annotations into memory...
Done (t=0.03s)
creating index...
index created!
Loading and preparing results...
DONE (t=0.81s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=7.45s).
Accumulating evaluation results...
DONE (t=1.21s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.375
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.636
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.390
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.168
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.476
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.711
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.320
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.444
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.451
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.254
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.580
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.778
