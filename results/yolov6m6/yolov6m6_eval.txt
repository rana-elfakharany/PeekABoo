Namespace(data='../SeaDronesSee-Yolov8/test.yaml', weights='./runs/train/yolov6m6/weights/best_ckpt.pt', batch_size=32, img_size=1280, conf_thres=0.03, iou_thres=0.65, task='val', device='0', half=False, save_dir='runs/val/', name='yolov6m6', test_load_size=638, letterbox_return_int=True, scale_exact=True, force_no_pad=True, not_infer_on_rect=True, reproduce_640_eval=True, eval_config_file='./configs/experiment/eval_640_repro.py', do_coco_metric=True, do_pr_metric=True, plot_curve=True, plot_confusion_matrix=True, verbose=True, config_file='')
Loading checkpoint from ./runs/train/yolov6m6/weights/best_ckpt.pt

Fusing model...
/localHome/sezrship/anaconda3/envs/torch/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Switch model to deploy modality.
Model Summary: Params: 79.53M, Gflops: 378.83
Val: Checking formats of labels with 8 process(es): 
  0%|          | 0/3279 [00:00<?, ?it/s]3073 label(s) found, 0 label(s) missing, 822 label(s) empty, 0 invalid label files:  94%|█████████▎| 3073/3279 [00:00<00:00, 30727.03it/s]3279 label(s) found, 0 label(s) missing, 852 label(s) empty, 0 invalid label files: 100%|██████████| 3279/3279 [00:00<00:00, 32378.04it/s]
Convert to COCO format
  0%|          | 0/3279 [00:00<?, ?it/s]100%|██████████| 3279/3279 [00:00<00:00, 34174.09it/s]
Convert to COCO format finished. Resutls saved in /localHome/sezrship/YOLOv6/SeaDronesSee-Yolov8/annotations/instances_test.json
Val: Final numbers of valid images: 3279/ labels: 3279. 
0.6s for dataset initialization.
Inferencing model in val datasets.:   0%|               | 0/103 [00:00<?, ?it/s]Inferencing model in val datasets.:   1%|       | 1/103 [00:03<06:03,  3.56s/it]Inferencing model in val datasets.:   2%|▏      | 2/103 [00:04<03:00,  1.78s/it]Inferencing model in val datasets.:   3%|▏      | 3/103 [00:04<01:55,  1.15s/it]Inferencing model in val datasets.:   4%|▎      | 4/103 [00:04<01:23,  1.18it/s]Inferencing model in val datasets.:   5%|▎      | 5/103 [00:05<01:09,  1.40it/s]Inferencing model in val datasets.:   6%|▍      | 6/103 [00:05<00:59,  1.63it/s]Inferencing model in val datasets.:   7%|▍      | 7/103 [00:06<00:50,  1.89it/s]Inferencing model in val datasets.:   8%|▌      | 8/103 [00:06<00:45,  2.10it/s]Inferencing model in val datasets.:   9%|▌      | 9/103 [00:06<00:41,  2.29it/s]Inferencing model in val datasets.:  10%|▌     | 10/103 [00:07<00:40,  2.28it/s]Inferencing model in val datasets.:  11%|▋     | 11/103 [00:07<00:38,  2.42it/s]Inferencing model in val datasets.:  12%|▋     | 12/103 [00:08<00:36,  2.52it/s]Inferencing model in val datasets.:  13%|▊     | 13/103 [00:08<00:35,  2.53it/s]Inferencing model in val datasets.:  14%|▊     | 14/103 [00:08<00:37,  2.38it/s]Inferencing model in val datasets.:  15%|▊     | 15/103 [00:09<00:36,  2.43it/s]Inferencing model in val datasets.:  16%|▉     | 16/103 [00:09<00:34,  2.54it/s]Inferencing model in val datasets.:  17%|▉     | 17/103 [00:09<00:32,  2.65it/s]Inferencing model in val datasets.:  17%|█     | 18/103 [00:10<00:33,  2.51it/s]Inferencing model in val datasets.:  18%|█     | 19/103 [00:10<00:32,  2.55it/s]Inferencing model in val datasets.:  19%|█▏    | 20/103 [00:11<00:32,  2.55it/s]Inferencing model in val datasets.:  20%|█▏    | 21/103 [00:11<00:31,  2.60it/s]Inferencing model in val datasets.:  21%|█▎    | 22/103 [00:11<00:31,  2.60it/s]Inferencing model in val datasets.:  22%|█▎    | 23/103 [00:12<00:30,  2.59it/s]Inferencing model in val datasets.:  23%|█▍    | 24/103 [00:12<00:30,  2.61it/s]Inferencing model in val datasets.:  24%|█▍    | 25/103 [00:13<00:29,  2.66it/s]Inferencing model in val datasets.:  25%|█▌    | 26/103 [00:13<00:29,  2.65it/s]Inferencing model in val datasets.:  26%|█▌    | 27/103 [00:13<00:28,  2.67it/s]Inferencing model in val datasets.:  27%|█▋    | 28/103 [00:14<00:28,  2.65it/s]Inferencing model in val datasets.:  28%|█▋    | 29/103 [00:14<00:27,  2.66it/s]Inferencing model in val datasets.:  29%|█▋    | 30/103 [00:14<00:27,  2.68it/s]Inferencing model in val datasets.:  30%|█▊    | 31/103 [00:15<00:27,  2.64it/s]Inferencing model in val datasets.:  31%|█▊    | 32/103 [00:15<00:27,  2.60it/s]Inferencing model in val datasets.:  32%|█▉    | 33/103 [00:16<00:26,  2.61it/s]Inferencing model in val datasets.:  33%|█▉    | 34/103 [00:16<00:26,  2.62it/s]Inferencing model in val datasets.:  34%|██    | 35/103 [00:16<00:26,  2.59it/s]Inferencing model in val datasets.:  35%|██    | 36/103 [00:17<00:25,  2.61it/s]Inferencing model in val datasets.:  36%|██▏   | 37/103 [00:17<00:25,  2.59it/s]Inferencing model in val datasets.:  37%|██▏   | 38/103 [00:18<00:25,  2.59it/s]Inferencing model in val datasets.:  38%|██▎   | 39/103 [00:18<00:24,  2.60it/s]Inferencing model in val datasets.:  39%|██▎   | 40/103 [00:18<00:24,  2.58it/s]Inferencing model in val datasets.:  40%|██▍   | 41/103 [00:19<00:24,  2.54it/s]Inferencing model in val datasets.:  41%|██▍   | 42/103 [00:19<00:25,  2.42it/s]Inferencing model in val datasets.:  42%|██▌   | 43/103 [00:20<00:26,  2.30it/s]Inferencing model in val datasets.:  43%|██▌   | 44/103 [00:20<00:27,  2.17it/s]Inferencing model in val datasets.:  44%|██▌   | 45/103 [00:21<00:27,  2.08it/s]Inferencing model in val datasets.:  45%|██▋   | 46/103 [00:21<00:28,  2.02it/s]Inferencing model in val datasets.:  46%|██▋   | 47/103 [00:22<00:26,  2.08it/s]Inferencing model in val datasets.:  47%|██▊   | 48/103 [00:22<00:25,  2.15it/s]Inferencing model in val datasets.:  48%|██▊   | 49/103 [00:22<00:23,  2.30it/s]Inferencing model in val datasets.:  49%|██▉   | 50/103 [00:23<00:22,  2.39it/s]Inferencing model in val datasets.:  50%|██▉   | 51/103 [00:23<00:21,  2.40it/s]Inferencing model in val datasets.:  50%|███   | 52/103 [00:24<00:22,  2.28it/s]Inferencing model in val datasets.:  51%|███   | 53/103 [00:24<00:22,  2.26it/s]Inferencing model in val datasets.:  52%|███▏  | 54/103 [00:25<00:22,  2.19it/s]Inferencing model in val datasets.:  53%|███▏  | 55/103 [00:25<00:22,  2.17it/s]Inferencing model in val datasets.:  54%|███▎  | 56/103 [00:26<00:21,  2.17it/s]Inferencing model in val datasets.:  55%|███▎  | 57/103 [00:26<00:21,  2.19it/s]Inferencing model in val datasets.:  56%|███▍  | 58/103 [00:27<00:20,  2.19it/s]Inferencing model in val datasets.:  57%|███▍  | 59/103 [00:27<00:21,  2.07it/s]Inferencing model in val datasets.:  58%|███▍  | 60/103 [00:28<00:20,  2.11it/s]Inferencing model in val datasets.:  59%|███▌  | 61/103 [00:28<00:19,  2.14it/s]Inferencing model in val datasets.:  60%|███▌  | 62/103 [00:28<00:19,  2.15it/s]Inferencing model in val datasets.:  61%|███▋  | 63/103 [00:29<00:18,  2.16it/s]Inferencing model in val datasets.:  62%|███▋  | 64/103 [00:29<00:18,  2.16it/s]Inferencing model in val datasets.:  63%|███▊  | 65/103 [00:30<00:17,  2.15it/s]Inferencing model in val datasets.:  64%|███▊  | 66/103 [00:30<00:17,  2.07it/s]Inferencing model in val datasets.:  65%|███▉  | 67/103 [00:31<00:17,  2.09it/s]Inferencing model in val datasets.:  66%|███▉  | 68/103 [00:31<00:16,  2.07it/s]Inferencing model in val datasets.:  67%|████  | 69/103 [00:32<00:16,  2.07it/s]Inferencing model in val datasets.:  68%|████  | 70/103 [00:32<00:16,  2.04it/s]Inferencing model in val datasets.:  69%|████▏ | 71/103 [00:33<00:16,  1.94it/s]Inferencing model in val datasets.:  70%|████▏ | 72/103 [00:33<00:15,  2.01it/s]Inferencing model in val datasets.:  71%|████▎ | 73/103 [00:34<00:14,  2.10it/s]Inferencing model in val datasets.:  72%|████▎ | 74/103 [00:34<00:13,  2.17it/s]Inferencing model in val datasets.:  73%|████▎ | 75/103 [00:35<00:12,  2.16it/s]Inferencing model in val datasets.:  74%|████▍ | 76/103 [00:35<00:12,  2.17it/s]Inferencing model in val datasets.:  75%|████▍ | 77/103 [00:36<00:12,  2.15it/s]Inferencing model in val datasets.:  76%|████▌ | 78/103 [00:36<00:11,  2.17it/s]Inferencing model in val datasets.:  77%|████▌ | 79/103 [00:36<00:10,  2.22it/s]Inferencing model in val datasets.:  78%|████▋ | 80/103 [00:37<00:10,  2.27it/s]Inferencing model in val datasets.:  79%|████▋ | 81/103 [00:37<00:09,  2.39it/s]Inferencing model in val datasets.:  80%|████▊ | 82/103 [00:38<00:08,  2.43it/s]Inferencing model in val datasets.:  81%|████▊ | 83/103 [00:38<00:08,  2.42it/s]Inferencing model in val datasets.:  82%|████▉ | 84/103 [00:38<00:07,  2.41it/s]Inferencing model in val datasets.:  83%|████▉ | 85/103 [00:39<00:07,  2.46it/s]Inferencing model in val datasets.:  83%|█████ | 86/103 [00:39<00:06,  2.51it/s]Inferencing model in val datasets.:  84%|█████ | 87/103 [00:40<00:06,  2.51it/s]Inferencing model in val datasets.:  85%|█████▏| 88/103 [00:40<00:06,  2.47it/s]Inferencing model in val datasets.:  86%|█████▏| 89/103 [00:40<00:05,  2.41it/s]Inferencing model in val datasets.:  87%|█████▏| 90/103 [00:41<00:05,  2.35it/s]Inferencing model in val datasets.:  88%|█████▎| 91/103 [00:41<00:05,  2.34it/s]Inferencing model in val datasets.:  89%|█████▎| 92/103 [00:42<00:04,  2.30it/s]Inferencing model in val datasets.:  90%|█████▍| 93/103 [00:42<00:04,  2.27it/s]Inferencing model in val datasets.:  91%|█████▍| 94/103 [00:43<00:03,  2.28it/s]Inferencing model in val datasets.:  92%|█████▌| 95/103 [00:43<00:03,  2.28it/s]Inferencing model in val datasets.:  93%|█████▌| 96/103 [00:44<00:03,  2.13it/s]Inferencing model in val datasets.:  94%|█████▋| 97/103 [00:44<00:02,  2.10it/s]Inferencing model in val datasets.:  95%|█████▋| 98/103 [00:45<00:02,  2.11it/s]Inferencing model in val datasets.:  96%|█████▊| 99/103 [00:45<00:01,  2.16it/s]Inferencing model in val datasets.:  97%|████▊| 100/103 [00:46<00:01,  2.18it/s]Inferencing model in val datasets.:  98%|████▉| 101/103 [00:46<00:00,  2.21it/s]Inferencing model in val datasets.:  99%|████▉| 102/103 [00:46<00:00,  2.29it/s]Inferencing model in val datasets.: 100%|█████| 103/103 [00:47<00:00,  2.32it/s]Inferencing model in val datasets.: 100%|█████| 103/103 [00:47<00:00,  2.18it/s]
IOU 50 best mF1 thershold near 0.328.
Class                 Images      Labels     P@.5iou     R@.5iou    F1@.5iou      mAP@.5  mAP@.5:.95
all                     3279        8273       0.807       0.627       0.671       0.644       0.379
boat                    3279        2569       0.906       0.884       0.895       0.909       0.625
buoy                    3279         821       0.875       0.831       0.852       0.856       0.513
jetski                  3279         465       0.901       0.723       0.802       0.764       0.475
life_saving_appliances        3279         152       0.659      0.0855       0.151       0.108      0.0603
swimmer                 3279        4266       0.695       0.615       0.652       0.581       0.223

Evaluating speed.
Average pre-process time: 0.25 ms
Average inference time: 8.03 ms
Average NMS time: 0.71 ms

Evaluating mAP by pycocotools.
Saving runs/val/yolov6m6/predictions.json...
Class           Labeled_images      Labels     P@.5iou     R@.5iou    F1@.5iou      mAP@.5  mAP@.5:.95
all                     2427        8273       0.675        0.69       0.683       0.642        0.38
boat                    1558        2569       0.939        0.86       0.898       0.905       0.623
buoy                     654         821       0.875        0.83       0.852       0.853       0.513
jetski                   465         465       0.913        0.72       0.805       0.761       0.475
life_saving_appliances         134         152       0.333        0.13       0.187       0.112      0.0633
swimmer                 1209        4266       0.687        0.62       0.652        0.58       0.225
Results saved to runs/val/yolov6m6
loading annotations into memory...
Done (t=0.03s)
creating index...
index created!
Loading and preparing results...
DONE (t=0.90s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=8.01s).
Accumulating evaluation results...
DONE (t=1.28s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.380
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.642
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.404
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.169
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.485
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.711
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.329
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.456
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.463
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.254
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.599
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.783
