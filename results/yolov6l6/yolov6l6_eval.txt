Namespace(data='../SeaDronesSee-Yolov8/test.yaml', weights='./runs/train/LaS3l/weights/best_ckpt.pt', batch_size=32, img_size=1280, conf_thres=0.03, iou_thres=0.65, task='val', device='0', half=False, save_dir='runs/val/', name='yolov6l6', test_load_size=638, letterbox_return_int=True, scale_exact=True, force_no_pad=True, not_infer_on_rect=True, reproduce_640_eval=True, eval_config_file='./configs/experiment/eval_640_repro.py', do_coco_metric=True, do_pr_metric=True, plot_curve=True, plot_confusion_matrix=True, verbose=True, config_file='')
Loading checkpoint from ./runs/train/LaS3l/weights/best_ckpt.pt

Fusing model...
/localHome/sezrship/anaconda3/envs/torch/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Switch model to deploy modality.
Model Summary: Params: 140.21M, Gflops: 672.46
Val: Checking formats of labels with 8 process(es): 
  0%|          | 0/3279 [00:00<?, ?it/s]2570 label(s) found, 0 label(s) missing, 724 label(s) empty, 0 invalid label files:  78%|███████▊  | 2570/3279 [00:00<00:00, 25684.90it/s]3279 label(s) found, 0 label(s) missing, 852 label(s) empty, 0 invalid label files: 100%|██████████| 3279/3279 [00:00<00:00, 27356.01it/s]
Convert to COCO format
  0%|          | 0/3279 [00:00<?, ?it/s]100%|██████████| 3279/3279 [00:00<00:00, 145728.45it/s]
Convert to COCO format finished. Resutls saved in /localHome/sezrship/YOLOv6/SeaDronesSee-Yolov8/annotations/instances_test.json
Val: Final numbers of valid images: 3279/ labels: 3279. 
0.5s for dataset initialization.
Inferencing model in val datasets.:   0%|               | 0/103 [00:00<?, ?it/s]Inferencing model in val datasets.:   1%|       | 1/103 [00:04<07:01,  4.13s/it]Inferencing model in val datasets.:   2%|▏      | 2/103 [00:05<03:48,  2.26s/it]Inferencing model in val datasets.:   3%|▏      | 3/103 [00:05<02:40,  1.60s/it]Inferencing model in val datasets.:   4%|▎      | 4/103 [00:06<02:01,  1.22s/it]Inferencing model in val datasets.:   5%|▎      | 5/103 [00:07<01:41,  1.03s/it]Inferencing model in val datasets.:   6%|▍      | 6/103 [00:07<01:30,  1.07it/s]Inferencing model in val datasets.:   7%|▍      | 7/103 [00:08<01:24,  1.14it/s]Inferencing model in val datasets.:   8%|▌      | 8/103 [00:09<01:16,  1.24it/s]Inferencing model in val datasets.:   9%|▌      | 9/103 [00:10<01:10,  1.33it/s]Inferencing model in val datasets.:  10%|▌     | 10/103 [00:10<01:12,  1.28it/s]Inferencing model in val datasets.:  11%|▋     | 11/103 [00:11<01:07,  1.36it/s]Inferencing model in val datasets.:  12%|▋     | 12/103 [00:12<01:05,  1.39it/s]Inferencing model in val datasets.:  13%|▊     | 13/103 [00:12<01:06,  1.35it/s]Inferencing model in val datasets.:  14%|▊     | 14/103 [00:13<01:06,  1.34it/s]Inferencing model in val datasets.:  15%|▊     | 15/103 [00:14<01:04,  1.36it/s]Inferencing model in val datasets.:  16%|▉     | 16/103 [00:15<01:07,  1.29it/s]Inferencing model in val datasets.:  17%|▉     | 17/103 [00:15<01:03,  1.36it/s]Inferencing model in val datasets.:  17%|█     | 18/103 [00:16<01:00,  1.39it/s]Inferencing model in val datasets.:  18%|█     | 19/103 [00:17<01:01,  1.36it/s]Inferencing model in val datasets.:  19%|█▏    | 20/103 [00:18<01:02,  1.33it/s]Inferencing model in val datasets.:  20%|█▏    | 21/103 [00:18<00:59,  1.39it/s]Inferencing model in val datasets.:  21%|█▎    | 22/103 [00:19<00:57,  1.41it/s]Inferencing model in val datasets.:  22%|█▎    | 23/103 [00:20<01:00,  1.32it/s]Inferencing model in val datasets.:  23%|█▍    | 24/103 [00:21<00:57,  1.38it/s]Inferencing model in val datasets.:  24%|█▍    | 25/103 [00:21<00:54,  1.43it/s]Inferencing model in val datasets.:  25%|█▌    | 26/103 [00:22<00:55,  1.40it/s]Inferencing model in val datasets.:  26%|█▌    | 27/103 [00:23<00:55,  1.38it/s]Inferencing model in val datasets.:  27%|█▋    | 28/103 [00:23<00:53,  1.40it/s]Inferencing model in val datasets.:  28%|█▋    | 29/103 [00:24<00:52,  1.42it/s]Inferencing model in val datasets.:  29%|█▋    | 30/103 [00:25<00:54,  1.33it/s]Inferencing model in val datasets.:  30%|█▊    | 31/103 [00:26<00:52,  1.38it/s]Inferencing model in val datasets.:  31%|█▊    | 32/103 [00:26<00:50,  1.41it/s]Inferencing model in val datasets.:  32%|█▉    | 33/103 [00:27<00:51,  1.36it/s]Inferencing model in val datasets.:  33%|█▉    | 34/103 [00:28<00:50,  1.36it/s]Inferencing model in val datasets.:  34%|██    | 35/103 [00:28<00:49,  1.37it/s]Inferencing model in val datasets.:  35%|██    | 36/103 [00:29<00:48,  1.39it/s]Inferencing model in val datasets.:  36%|██▏   | 37/103 [00:30<00:50,  1.30it/s]Inferencing model in val datasets.:  37%|██▏   | 38/103 [00:31<00:47,  1.35it/s]Inferencing model in val datasets.:  38%|██▎   | 39/103 [00:31<00:46,  1.38it/s]Inferencing model in val datasets.:  39%|██▎   | 40/103 [00:32<00:46,  1.36it/s]Inferencing model in val datasets.:  40%|██▍   | 41/103 [00:33<00:46,  1.34it/s]Inferencing model in val datasets.:  41%|██▍   | 42/103 [00:34<00:45,  1.34it/s]Inferencing model in val datasets.:  42%|██▌   | 43/103 [00:35<00:48,  1.23it/s]Inferencing model in val datasets.:  43%|██▌   | 44/103 [00:36<00:48,  1.21it/s]Inferencing model in val datasets.:  44%|██▌   | 45/103 [00:36<00:47,  1.22it/s]Inferencing model in val datasets.:  45%|██▋   | 46/103 [00:37<00:45,  1.24it/s]Inferencing model in val datasets.:  46%|██▋   | 47/103 [00:38<00:47,  1.18it/s]Inferencing model in val datasets.:  47%|██▊   | 48/103 [00:39<00:45,  1.20it/s]Inferencing model in val datasets.:  48%|██▊   | 49/103 [00:40<00:43,  1.25it/s]Inferencing model in val datasets.:  49%|██▉   | 50/103 [00:40<00:41,  1.27it/s]Inferencing model in val datasets.:  50%|██▉   | 51/103 [00:41<00:39,  1.31it/s]Inferencing model in val datasets.:  50%|███   | 52/103 [00:42<00:41,  1.23it/s]Inferencing model in val datasets.:  51%|███   | 53/103 [00:43<00:39,  1.26it/s]Inferencing model in val datasets.:  52%|███▏  | 54/103 [00:44<00:39,  1.25it/s]Inferencing model in val datasets.:  53%|███▏  | 55/103 [00:44<00:38,  1.23it/s]Inferencing model in val datasets.:  54%|███▎  | 56/103 [00:45<00:37,  1.24it/s]Inferencing model in val datasets.:  55%|███▎  | 57/103 [00:46<00:39,  1.17it/s]Inferencing model in val datasets.:  56%|███▍  | 58/103 [00:47<00:37,  1.20it/s]Inferencing model in val datasets.:  57%|███▍  | 59/103 [00:48<00:37,  1.18it/s]Inferencing model in val datasets.:  58%|███▍  | 60/103 [00:49<00:35,  1.21it/s]Inferencing model in val datasets.:  59%|███▌  | 61/103 [00:50<00:36,  1.16it/s]Inferencing model in val datasets.:  60%|███▌  | 62/103 [00:50<00:34,  1.19it/s]Inferencing model in val datasets.:  61%|███▋  | 63/103 [00:51<00:34,  1.16it/s]Inferencing model in val datasets.:  62%|███▋  | 64/103 [00:52<00:32,  1.19it/s]Inferencing model in val datasets.:  63%|███▊  | 65/103 [00:53<00:34,  1.11it/s]Inferencing model in val datasets.:  64%|███▊  | 66/103 [00:54<00:33,  1.11it/s]Inferencing model in val datasets.:  65%|███▉  | 67/103 [00:55<00:31,  1.14it/s]Inferencing model in val datasets.:  66%|███▉  | 68/103 [00:56<00:30,  1.17it/s]Inferencing model in val datasets.:  67%|████  | 69/103 [00:57<00:30,  1.12it/s]Inferencing model in val datasets.:  68%|████  | 70/103 [00:57<00:29,  1.12it/s]Inferencing model in val datasets.:  69%|████▏ | 71/103 [00:58<00:28,  1.14it/s]Inferencing model in val datasets.:  70%|████▏ | 72/103 [00:59<00:26,  1.15it/s]Inferencing model in val datasets.:  71%|████▎ | 73/103 [01:00<00:25,  1.18it/s]Inferencing model in val datasets.:  72%|████▎ | 74/103 [01:01<00:24,  1.21it/s]Inferencing model in val datasets.:  73%|████▎ | 75/103 [01:02<00:23,  1.19it/s]Inferencing model in val datasets.:  74%|████▍ | 76/103 [01:03<00:22,  1.18it/s]Inferencing model in val datasets.:  75%|████▍ | 77/103 [01:03<00:22,  1.14it/s]Inferencing model in val datasets.:  76%|████▌ | 78/103 [01:04<00:20,  1.19it/s]Inferencing model in val datasets.:  77%|████▌ | 79/103 [01:05<00:20,  1.19it/s]Inferencing model in val datasets.:  78%|████▋ | 80/103 [01:06<00:18,  1.25it/s]Inferencing model in val datasets.:  79%|████▋ | 81/103 [01:06<00:16,  1.31it/s]Inferencing model in val datasets.:  80%|████▊ | 82/103 [01:07<00:16,  1.24it/s]Inferencing model in val datasets.:  81%|████▊ | 83/103 [01:08<00:15,  1.27it/s]Inferencing model in val datasets.:  82%|████▉ | 84/103 [01:09<00:15,  1.25it/s]Inferencing model in val datasets.:  83%|████▉ | 85/103 [01:10<00:14,  1.26it/s]Inferencing model in val datasets.:  83%|█████ | 86/103 [01:10<00:12,  1.31it/s]Inferencing model in val datasets.:  84%|█████ | 87/103 [01:11<00:12,  1.29it/s]Inferencing model in val datasets.:  85%|█████▏| 88/103 [01:12<00:11,  1.27it/s]Inferencing model in val datasets.:  86%|█████▏| 89/103 [01:13<00:10,  1.30it/s]Inferencing model in val datasets.:  87%|█████▏| 90/103 [01:14<00:10,  1.23it/s]Inferencing model in val datasets.:  88%|█████▎| 91/103 [01:14<00:09,  1.27it/s]Inferencing model in val datasets.:  89%|█████▎| 92/103 [01:15<00:08,  1.26it/s]Inferencing model in val datasets.:  90%|█████▍| 93/103 [01:16<00:07,  1.27it/s]Inferencing model in val datasets.:  91%|█████▍| 94/103 [01:17<00:06,  1.29it/s]Inferencing model in val datasets.:  92%|█████▌| 95/103 [01:17<00:06,  1.28it/s]Inferencing model in val datasets.:  93%|█████▌| 96/103 [01:18<00:05,  1.24it/s]Inferencing model in val datasets.:  94%|█████▋| 97/103 [01:19<00:05,  1.17it/s]Inferencing model in val datasets.:  95%|█████▋| 98/103 [01:20<00:04,  1.21it/s]Inferencing model in val datasets.:  96%|█████▊| 99/103 [01:21<00:03,  1.21it/s]Inferencing model in val datasets.:  97%|████▊| 100/103 [01:22<00:02,  1.23it/s]Inferencing model in val datasets.:  98%|████▉| 101/103 [01:23<00:01,  1.21it/s]Inferencing model in val datasets.:  99%|████▉| 102/103 [01:23<00:00,  1.23it/s]Inferencing model in val datasets.: 100%|█████| 103/103 [01:24<00:00,  1.49it/s]Inferencing model in val datasets.: 100%|█████| 103/103 [01:24<00:00,  1.22it/s]
IOU 50 best mF1 thershold near 0.304.
Class                 Images      Labels     P@.5iou     R@.5iou    F1@.5iou      mAP@.5  mAP@.5:.95
all                     3279        8273       0.792       0.648       0.688        0.66       0.392
boat                    3279        2569       0.904       0.899       0.902       0.919       0.628
buoy                    3279         821       0.903       0.836       0.868       0.873       0.539
jetski                  3279         465       0.863       0.729        0.79       0.755       0.484
life_saving_appliances        3279         152       0.608       0.132       0.217        0.16        0.09
swimmer                 3279        4266       0.683       0.644       0.663       0.593       0.219

Evaluating speed.
Average pre-process time: 0.29 ms
Average inference time: 16.32 ms
Average NMS time: 1.87 ms

Evaluating mAP by pycocotools.
Saving runs/val/yolov6l6/predictions.json...
Class           Labeled_images      Labels     P@.5iou     R@.5iou    F1@.5iou      mAP@.5  mAP@.5:.95
all                     2427        8273        0.69        0.69        0.69       0.658       0.392
boat                    1558        2569       0.938        0.88       0.908       0.915       0.626
buoy                     654         821       0.897        0.84       0.868       0.869       0.539
jetski                   465         465        0.93        0.71       0.805       0.752       0.484
life_saving_appliances         134         152        0.39        0.21       0.273       0.163      0.0925
swimmer                 1209        4266       0.687        0.64       0.663       0.591       0.221
Results saved to runs/val/yolov6l6
loading annotations into memory...
Done (t=0.03s)
creating index...
index created!
Loading and preparing results...
DONE (t=0.51s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=6.08s).
Accumulating evaluation results...
DONE (t=0.89s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.392
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.658
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.410
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.487
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.694
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.338
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.468
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.475
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.297
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.587
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.764
